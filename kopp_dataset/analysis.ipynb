{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "TLDR:\n",
    "-\n",
    "- we have 534 patients with lateral videos: 25 patients with no lateral videos\n",
    "- 64 patients with videos from different acquisition dates\n",
    "- todo: swallows need to be extracted\n"
   ],
   "id": "fa9d0fc0f38203a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5a8f06048e979f74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Analysis of Kopp Dataset (Erlangen / Disphagia)\n",
    "TLDR: Disphagia dataset with uncut videos of swallows from different perspectives\n",
    "\n",
    "Pros:\n",
    "- patient information\n",
    "- labels for conditions\n",
    "\n",
    "Challenges / Todos:\n",
    "- [ ] multiple perspectives (1-20, ~5) -> Identify correct perspectives (heuristic or CNN Classification)\n",
    "    - perspectives: lateral, frontal, zoomed in lateral and movement doing scan\n",
    "    - [ ] sometimes >1 video from correct perspective -> choose one\n",
    "- [ ] uncut videos -> Identify swallows and cut videos\n",
    "- [ ] Some videos have movements in them (of patient or camera) -> further analysis\n",
    "- only disphagia, no normals\n",
    "\n",
    "Questions:\n",
    "- Swallow extraction\n",
    "- if we use different acquisition dates, how to handle them? age col needs to be adjusted"
   ],
   "id": "bf85b1df67bfc451"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1da9768669e8fe7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Folder Structure:\n",
    "- patient id dcm folders\n",
    "   - 560 patient identifiers\n",
    "  - every patient folder can have multiple subfolders/videos with dcm file\n",
    "- Diagnosen und Prozeduren folder\n",
    "   - Diagnosen_psuedonymisiert.csv\n",
    "      -  Columns: PATIENT_ID\tFALL_ID\tICD_CODE\tDIAGNOSE_DATUM\tGEWISSHEIT_ID\n",
    "      - 3,742 rows\n",
    "  - Prozeduren_pseudonymisiert.csv\n",
    "      - Columns: PATIENT_ID\tFALL_ID\tOPS_CODE PROZEDUR_DATUM\n",
    "      - 1,523 rows\n",
    "- extracted_videos_and_images folder\n",
    "   - extracted mp4 files from dcm files per video id\n",
    "- Kopp_Data_Overview.xlsx\n",
    "   - columns:\n",
    "      - Birth Year\n",
    "      - Age\n",
    "      - Sex\n",
    "      - Manufacturer\n",
    "      - Manufacturer's Model Name\n",
    "      - Device Serial Number\n",
    "      - Image/ Video Identifier\n",
    "      - Comments about the Image/ Video\n",
    "    -  3,018 rows\n",
    "    - prob. just extracted info from dicom files\n",
    "- README.md\n",
    "   - mentions test sample ids\n"
   ],
   "id": "9f8be5a54eba0484"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### get data",
   "id": "4225f799332ea5c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "videos_path = r\"\\\\fauad.fau.de\\shares\\ANKI\\Projects\\Swallowing\\Data\\from_Kopp\\extracted_videos_and_images\"",
   "id": "8ddcd3872f4e589f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# orientation labels\n",
    "orientation_labels_path = \"kopp_video_labels.csv\"\n",
    "df_orientation_labels = pd.read_csv(orientation_labels_path)\n",
    "df_orientation_labels.head()"
   ],
   "id": "1e1a6f51e6e6a95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# data overview\n",
    "overview_path = r\"\\\\fauad.fau.de\\shares\\ANKI\\Projects\\Swallowing\\Data\\from_Kopp\\Kopp_Data_Overview.xlsx\"\n",
    "df_overview = pd.read_excel(overview_path)\n",
    "df_overview.head()"
   ],
   "id": "349bf5b9e57812e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# diagnosis data\n",
    "diagnosis_path = r\"\\\\fauad.fau.de\\shares\\ANKI\\Projects\\Swallowing\\Data\\from_Kopp\\Diagnosen und Prozeduren\\Diagnosen_pseudonymisiert.csv\"\n",
    "df_diagnosis = pd.read_csv(diagnosis_path)\n",
    "df_diagnosis.head()"
   ],
   "id": "a23b16b1e0bfa1cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "82789a19d6caf882",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### process data",
   "id": "cf5cd082284e92fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### merge\n",
    "df_orientation_labels['video_id'] = df_orientation_labels['video_id'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "df_overview = df_overview.merge(df_orientation_labels, left_on='Image/ Video Identifier', right_on='video_id')\n"
   ],
   "id": "fff41a9381ae33cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# process date\n",
    "df_overview['Acquisition Date'] = pd.to_datetime(df_overview['Acquisition Date'], format='%Y%m%d')\n",
    "df_overview['Acquisition Date'] = df_overview['Acquisition Date'].dt.date\n",
    "df_overview['Acquisition Date'] = pd.to_datetime(df_overview['Acquisition Date'])\n",
    "\n",
    "# process age\n",
    "# for age column, remove last char from string and convert to int\n",
    "df_overview[\"Age\"] = df_overview[\"Age\"].apply(lambda x: int(x[:-1]))"
   ],
   "id": "fdc5df2788b8e0e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# video images folder -> we only are interested in the video files\n",
    "# get all video files\n",
    "video_files = [f.split('.')[0] for f in os.listdir(videos_path) if f.endswith('.mp4')]\n",
    "print(f\"Number of video files: {len(video_files)}\")\n",
    "\n",
    "# png files\n",
    "png_files = [f.split('.')[0] for f in os.listdir(videos_path) if f.endswith('.png')]\n",
    "print(f\"Number of png files: {len(png_files)}\")\n",
    "print(f\"Total number of files: {len(video_files) + len(png_files)}\")\n",
    "\n",
    "df_video_files = pd.DataFrame(video_files, columns=['Image/ Video Identifier'])\n",
    "df_video_files['PatID'] = df_video_files['Image/ Video Identifier'].apply(lambda x: x.split('_')[0])"
   ],
   "id": "3738bc8a977b3a9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# filter: only videos with label 1\n",
    "df_overview_lateral = df_overview[df_overview[\"label\"] == 1]"
   ],
   "id": "df5631bd7bc0dcca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### analysis",
   "id": "c3d8fc728b38f85a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Distribution of orientation labels",
   "id": "da216eee7afb5097"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_orientation_labels[\"label\"].value_counts()",
   "id": "56f4bd234eadc4c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot distribution of orientation labels\n",
    "df_orientation_labels[\"label\"].value_counts().plot(kind='bar')"
   ],
   "id": "2f03e9866d70fb62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_overview\n",
    "# create column that is a link to the video\n",
    "df_overview['video_link'] = df_overview['Image/ Video Identifier'].apply(lambda x: os.path.join(videos_path, f\"{x}.mp4\"))\n",
    "df_overview"
   ],
   "id": "1ffb9cf24d9475f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "plot one sample per class",
   "id": "c84f1d8b717f0048"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# i have 4 classes in the df_overview for column label\n",
    "# out of each class i want to sample one video and from that get the first frame\n",
    "# i want to make a plot with classes 1-4 with each having the first frame\n",
    "\n",
    "# get one video per class\n",
    "df_overview_sample = df_overview.groupby('label').sample(1)\n",
    "\n",
    "# List to store video frames and titles\n",
    "frames = []\n",
    "titles = []\n",
    "\n",
    "# Extract the first frame of each video\n",
    "for video_id in df_overview_sample['video_id']:\n",
    "    video_path = os.path.join(videos_path, f\"{video_id}.mp4\")\n",
    "    if os.path.exists(video_path):\n",
    "        # Capture the video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            # Convert BGR to RGB for proper visualization\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "            titles.append(video_id)\n",
    "        cap.release()\n",
    "\n",
    "# Create a plot with the frames\n",
    "fig, axes = plt.subplots(1, len(frames), figsize=(15, 5))\n",
    "if len(frames) == 1:\n",
    "    axes = [axes]  # Ensure axes is iterable for single video case\n",
    "for ax, frame, title in zip(axes, frames, titles):\n",
    "    ax.imshow(frame)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6f16d1086eff6753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from skvideo.io import vread\n",
    "def save_video_frames_plot(video_path, save_path):\n",
    "    \"\"\"\n",
    "    Display frames 3, 4, and 5 of the video side by side and prompt for a label.\n",
    "    Save the label to the CSV file.\n",
    "    \"\"\"\n",
    "    # Read the video\n",
    "    video_id = os.path.basename(video_path)\n",
    "    video = vread(video_path)\n",
    "\n",
    "    # Check if video has at least 15 frames\n",
    "    if len(video) < 15:\n",
    "        print(f\"Video {video_id} does not have enough frames. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Extract frames 0, middle and last\n",
    "    frame_indices = [0, int((len(video)/2)-1), len(video)-1]\n",
    "    frames = [video[i] for i in frame_indices]\n",
    "\n",
    "    # Display frames side by side\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    titles = [f\"Frame {i+1}\" for i in frame_indices]\n",
    "    for ax, frame, title in zip(axes, frames, titles):\n",
    "        ax.imshow(frame)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.suptitle(f\"Video: {video_id}\\n\")\n",
    "    #plt.show()\n",
    "    full_save_path = os.path.join(save_path, f\"{video_id}.png\")\n",
    "    # dont show plot, just save it\n",
    "    plt.savefig(full_save_path)\n",
    "\n",
    "df_overview_orientation_unsure = df_overview[df_overview[\"label\"] == 3].head(5)\n",
    "for video_id in df_overview_orientation_unsure['video_id']:\n",
    "    video_path = os.path.join(videos_path, f\"{video_id}.mp4\")\n",
    "    save_video_frames_plot(video_path, \"media/3\")"
   ],
   "id": "4aaf2377de6d830e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "frames distribution for lateral (takes 1min)",
   "id": "3846b4c9a2b8b9e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# analyze how many frames we have per video\n",
    "def get_frame_count(video_path):\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total frame count in the video\n",
    "        cap.release()\n",
    "        return frame_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# get frame count for all videos and save it as column in df -> takes 1min\n",
    "df_overview_lateral['Frame Count'] = df_overview_lateral['Image/ Video Identifier'].apply(lambda x: get_frame_count(os.path.join(videos_path, x + '.mp4')))"
   ],
   "id": "b2a0dae916449ae8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "84d118da79c617b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create histogram of frame count\n",
    "plt.hist(df_overview_lateral['Frame Count'], bins=100)\n",
    "# add x y axis labels\n",
    "plt.xlabel(\"Frame Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Frame Count Distribution per full video\")\n",
    "\n",
    "print(\"Frame Count Stats:\")\n",
    "print(df_overview_lateral['Frame Count'].describe())\n",
    "\n",
    "frame_value_counts = df_overview_lateral['Frame Count'].value_counts()"
   ],
   "id": "80f662d03ec3889d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lateral Video Distribution per patient",
   "id": "f66811bc7154e5e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_videos_per_patient = df_overview_lateral.groupby('PatID').size()\n",
    "print(df_videos_per_patient.describe())"
   ],
   "id": "b4db7dd7aaec9456",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# how many video ids do we have per patient - group by PatID\n",
    "# create histogram\n",
    "plt.hist(df_overview_lateral.groupby('PatID').size(), bins=50)\n",
    "# add x y axis labels\n",
    "plt.xlabel(\"Number of Videos\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Number of Lateral Videos per Patient\")"
   ],
   "id": "451437797a354094",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print out video ids grouped by patient id, where we have more than 1 video\n",
    "print(df_overview_lateral.groupby('PatID').filter(lambda x: len(x) > 1).groupby('PatID')['Image/ Video Identifier'].apply(list))"
   ],
   "id": "2abb6e2ecd81479",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# show video with 19 frames\n",
    "video_path = os.path.join(videos_path, df_overview_lateral[df_overview_lateral['Frame Count'] == 19].iloc[0]['Image/ Video Identifier'] + '.mp4')\n",
    "video_path"
   ],
   "id": "7d1892994049396e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ed1b1985dfd1c29e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How many patients have no lateral video?",
   "id": "5a7f6415dec74233"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# how many patients are there with no label 1 video label\n",
    "df_overview[df_overview['PatID'].isin(df_overview_lateral['PatID']) == False].groupby('PatID').size()"
   ],
   "id": "b50b83909c9a5836",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_overview_lateral['PatID'].nunique()",
   "id": "3bf751bc00c50407",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Distribution of Acquisition dates",
   "id": "aded8188e64b1f4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group by PatID and check for consistency in Acquisition Date\n",
    "inconsistent_patients_acquisition = df_overview_lateral.groupby('PatID')['Acquisition Date'].nunique()\n",
    "\n",
    "# Filter for patients with more than one unique acquisition date\n",
    "inconsistent_acquisitions_patient_ids = inconsistent_patients_acquisition[inconsistent_patients_acquisition > 1].index.tolist()\n",
    "\n",
    "df_inconsistent_acquisition = df_overview_lateral[df_overview_lateral['PatID'].isin(inconsistent_acquisitions_patient_ids)].groupby('PatID')['Acquisition Date'].agg(['nunique', 'min', 'max'])\n",
    "df_inconsistent_acquisition['Max Time Difference (days)'] = (df_inconsistent_acquisition['max'] - df_inconsistent_acquisition['min']).dt.days\n",
    "df_inconsistent_acquisition#.head()"
   ],
   "id": "784bfcc1df56a10c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# how many patients have more than 1 video\n",
    "print(f\"Number of patients with more than 1 video: {len(df_videos_per_patient[df_videos_per_patient > 1])}\")\n",
    "# how many patients have more than 1 video from different acquisition dates\n",
    "print(f\"Number of patients with more than 1 video from different acquisition dates: {len(df_inconsistent_acquisition)}\")"
   ],
   "id": "1d408399a440a0eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot max time difference as histogram\n",
    "plt.hist(df_inconsistent_acquisition['Max Time Difference (days)'], bins=10)\n",
    "# add x y axis labels\n",
    "plt.xlabel(\"Max Time Difference (days)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Max Acquisition Time Difference Distribution per Patient\")"
   ],
   "id": "3d2f958a18694e2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot distribution of acquisition dates per year\n",
    "df_overview_lateral['Acquisition Date'].dt.year.value_counts().sort_index().plot(kind='bar')\n",
    "# add x y axis labels\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Acquisition Date Distribution per Year\")"
   ],
   "id": "be9f3c162f6745a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "age\n",
    "\n",
    "note: age at acquisition is prob. from first acquisition date?"
   ],
   "id": "d1a470413a5aff36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot distribution of age\n",
    "print(\"Age Stats:\")\n",
    "print(df_overview_lateral[\"Age\"].describe())"
   ],
   "id": "ff412cbc91ced359",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Determine the bin range\n",
    "min_age = df_overview_lateral[\"Age\"].min()\n",
    "max_age = df_overview_lateral[\"Age\"].max()\n",
    "bins = range(min_age, max_age + 2, 5)  # Bin width of 2 years\n",
    "\n",
    "# Plot histogram for all data combined (no gender differentiation)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(\n",
    "    df_overview_lateral[\"Age\"],\n",
    "    bins=bins,\n",
    "    density=True,\n",
    "    edgecolor='black'\n",
    ")\n",
    "plt.ylim(0, 0.01)  # Adjust based on expected density range\n",
    "plt.yticks([0, 0.01, 0.02, 0.03, 0.04, 0.05])  # Standardized ticks\n",
    "\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(\"Normalized Age Distribution\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "id": "5777a89d721175a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "gender distribution",
   "id": "a5165df01de3662c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_gender = df_overview_lateral[[\"PatID\", \"Sex\"]].drop_duplicates()\n",
    "print(df_gender[\"Sex\"].value_counts())\n",
    "print(round(df_gender[\"Sex\"].value_counts() / len(df_gender), 2))"
   ],
   "id": "6f4f503356cdc469",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "age distribution per gender\n",
   "id": "5f54d7194c63ad8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Adjust bins to be consistent for both genders\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Determine a consistent bin range for both genders\n",
    "min_age = df_overview_lateral[\"Age\"].min()\n",
    "max_age = df_overview_lateral[\"Age\"].max()\n",
    "bins = range(min_age, max_age + 2, 5)  # Bin width of 2 years\n",
    "\n",
    "for gender in df_overview_lateral[\"Sex\"].unique():\n",
    "    subset = df_overview_lateral[df_overview_lateral[\"Sex\"] == gender]\n",
    "    plt.hist(subset[\"Age\"], bins=bins, alpha=0.6, density=True, label=f\"{gender}\", edgecolor='black')\n",
    "\n",
    "plt.ylim(0, 0.01)  # Adjust based on expected density range\n",
    "plt.yticks([0, 0.01, 0.02, 0.03, 0.04, 0.05])  # Standardized ticks\n",
    "\n",
    "plt.title(\"Normalized Age Distribution by Gender with Consistent Bins\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"Gender\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ],
   "id": "8e1306e7e857be4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Age of Men: {df_overview_lateral[df_overview_lateral[\"Sex\"] == \"M\"][\"Age\"].describe()}\\n\")",
   "id": "a2d20ad523b59fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Age of Women: {df_overview_lateral[df_overview_lateral[\"Sex\"] == \"F\"][\"Age\"].describe()}\")",
   "id": "659b2e6e3dd38569",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "92132ddb5723466f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### diagnosis + procedures",
   "id": "a30c45be7e5dda01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "how many diagnosis per patient",
   "id": "accbd1005390a5ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_diagnosis.groupby('PATIENT_ID').size().sort_values(ascending=False)",
   "id": "528cfd52d5e097bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# histogram of diagnosis per patient\n",
    "plt.hist(df_diagnosis.groupby('PATIENT_ID').size(), bins=50)"
   ],
   "id": "c3d1afb7f9e5a084",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# show all other columns for group by patient id per patient\n",
    "df_diagnosis[df_diagnosis[\"PATIENT_ID\"] == 1911001813]#.groupby('PATIENT_ID')"
   ],
   "id": "cf0fb5af5631e6a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "type of diagnosis\n",
    "\n"
   ],
   "id": "a8db722808d1a795"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_diagnosis[\"FALL_ID\"].value_counts()",
   "id": "8330104d9df55630",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "diagnosis confidence\n",
    "info:\n",
    "- ZN    Zustand nach\n",
    "- VA    Verdachtsdiagnose\n",
    "- GE    gesicherte Diagnose\n",
    "- AU    ausgeschlossene Diagnose\n",
    "- „ein Leerzeichen“\n",
    "    - -> bei ambulanten Fällen: Annahme gesicherte Diagnose\n",
    "    - -> bei stationären Fällen: GEWISSHEIT_ID ist immer leer"
   ],
   "id": "5a8e0703ec857673"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_diagnosis[\"GEWISSHEIT_ID\"].value_counts()",
   "id": "68f38b101b2aeb95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## IQA",
   "id": "1a82e9b05e36a6bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "video resolution (of first frame)",
   "id": "68e065f559aefb9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# do all the videos have the same resolution?\n",
    "# go through all the videos first frame and check resolution\n",
    "resolution = []\n",
    "for video_id in df_overview_lateral['Image/ Video Identifier']:\n",
    "    video_path = os.path.join(videos_path, f\"{video_id}.mp4\")\n",
    "    if os.path.exists(video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            resolution.append(frame.shape)\n",
    "        cap.release()\n",
    "df_overview_lateral['Resolution'] = resolution"
   ],
   "id": "418c9af4bdde1462",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_overview_lateral['Resolution'].value_counts()",
   "id": "370260c52b5a257d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print out video ids with different resolutions\n",
    "df_overview_lateral[df_overview_lateral['Resolution'] != (1024, 1024, 3)][['Image/ Video Identifier', 'Resolution']]"
   ],
   "id": "866ab281a9f3f61e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## artefacts - black frames present?\n",
   "id": "b2e25ef18a38fc6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "dynamic range analysis",
   "id": "2da4cba002a14780"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dynamic range analysis\n",
    "# = intensity histogram\n",
    "\n",
    "# plot the intensity histogram of the first frame of a video\n",
    "video_path = os.path.join(videos_path, df_overview_lateral.iloc[0]['Image/ Video Identifier'] + '.mp4')\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "success, frame = cap.read()\n",
    "if success:\n",
    "    # Convert to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    plt.hist(gray_frame.ravel(), bins=256, range=[0, 256])\n",
    "    plt.title(\"Intensity Histogram of the First Frame\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "cap.release()\n",
    "\n",
    "\n"
   ],
   "id": "7865250d7afa0b43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming `df_overview_lateral` and `videos_path` are already defined\n",
    "video_files = [\n",
    "    os.path.join(videos_path, f\"{video_id}.mp4\")\n",
    "    for video_id in df_overview_lateral['Image/ Video Identifier']\n",
    "]\n",
    "\n",
    "# Initialize an empty histogram array with 256 bins\n",
    "all_histograms = np.zeros(256, dtype=np.float64)  # Use float64 for accumulation\n",
    "\n",
    "# Process each video\n",
    "for video_path in tqdm(video_files, desc=\"Processing Videos\"):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # Randomly sample a frame index\n",
    "    if frame_count > 0:\n",
    "        random_frame_idx = random.randint(0, frame_count - 1)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame_idx)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            # Convert the frame to grayscale\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Compute the histogram for the grayscale frame\n",
    "            hist, _ = np.histogram(gray_frame.ravel(), bins=256, range=[0, 256])\n",
    "            all_histograms += hist  # Accumulate histograms\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Check if any valid histograms were aggregated\n",
    "if all_histograms.sum() == 0:\n",
    "    print(\"No valid frames were processed. Please check the video paths and frame selection.\")\n",
    "else:\n",
    "    # Normalize the aggregated histogram for visualization\n",
    "    all_histograms_normalized = all_histograms / all_histograms.sum()\n",
    "\n",
    "    # Plot the aggregated histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(256), all_histograms_normalized, width=1, edgecolor='black')\n",
    "    plt.title(\"Aggregated Intensity Histogram Across Videos\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Normalized Frequency\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ],
   "id": "e3741d4aa2b2e914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_histograms",
   "id": "a46626d3e7e1efbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ee6cb871c19b966b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### niqe score",
   "id": "9d7b4851d91944bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import skvideo # note: skvideo is pain to work with -> i use custom version: pip install -e .\n",
    "import skvideo.measure\n",
    "from skvideo.io import vread\n",
    "import numpy as np\n",
    "np.float = np.float64\n",
    "np.int = np.int_\n",
    "import skvideo.measure\n",
    "from skvideo.io import vread\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def compute_video_niqe(video_path, first_frame_only=False):\n",
    "    \"\"\"\n",
    "    Compute the NIQE score for a video, either across all frames or just the first frame.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path (str): Path to the video file.\n",
    "    - first_frame_only (bool): If True, compute NIQE for only the first frame.\n",
    "\n",
    "    Returns:\n",
    "    - float: Median NIQE score (or NIQE score for the first frame if `first_frame_only` is True).\n",
    "    \"\"\"\n",
    "    # Load the video\n",
    "    video = vread(video_path)\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    #print(f\"Original video shape: {video.shape}\")\n",
    "\n",
    "    # Convert to grayscale if not already (use only the first channel)\n",
    "    if len(video.shape) == 4:  # If the video has channels\n",
    "        video = video[:, :, :, 0]  # Extract the luminance channel (grayscale)\n",
    "    #print(f\"Grayscale video shape: {video.shape}\")\n",
    "\n",
    "    # Select frames\n",
    "    if first_frame_only:\n",
    "        video = video[:1]  # Keep only the first frame\n",
    "        #print(\"Computing NIQE for the first frame only.\")\n",
    "\n",
    "    # Compute NIQE scores\n",
    "    niqe_scores = skvideo.measure.niqe(video)\n",
    "    #print(f\"NIQE Scores: {niqe_scores}\")\n",
    "\n",
    "    # Compute the median score (or single score if first frame only)\n",
    "    median_score = np.median(niqe_scores)\n",
    "    #print(f\"Median NIQE Score: {median_score}\")\n",
    "    return median_score\n",
    "\n",
    "def compute_niqe_for_videos_in_path(df, first_frame_only=False):\n",
    "    \"\"\"\n",
    "    Compute NIQE scores for all videos in a directory.\n",
    "\n",
    "    Parameters:\n",
    "    - videos_path (str): Path to the directory containing video files.\n",
    "    - first_frame_only (bool): If True, compute NIQE only for the first frame of each video.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with video file paths as keys and median NIQE scores as values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store results\n",
    "    niqe_scores = []\n",
    "    # Compute NIQE for each video\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            abs_path = os.path.join(videos_path, row[\"video_id\"] + '.mp4')\n",
    "            median_score = compute_video_niqe(abs_path, first_frame_only=first_frame_only)\n",
    "            niqe_scores.append(median_score)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_path}: {e}\")\n",
    "            niqe_scores.append(None)\n",
    "    df[\"niqe\"] = niqe_scores\n",
    "\n",
    "    return df\n",
    "\n",
    "compute_first_frame_only = True  # Set to True to compute NIQE only for the first frame\n",
    "# Compute NIQE scores for all videos in the directory\n",
    "results = compute_niqe_for_videos_in_path(df_overview_lateral, first_frame_only=compute_first_frame_only)\n"
   ],
   "id": "297b9ad120ad9f47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# round niqe scores\n",
    "results[\"niqe\"] = results[\"niqe\"].round(2)\n",
    "results[\"niqe\"].describe()"
   ],
   "id": "3ab5a4b65f5c3515",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "highest niqe",
   "id": "296e2dea75147265"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the first frame of the video with the highest NIQE score\n",
    "highest_niqe_video = results[results[\"niqe\"] == results[\"niqe\"].max()].iloc[0]\n",
    "video_path = os.path.join(videos_path, highest_niqe_video[\"video_id\"] + '.mp4')\n",
    "print(f\"Video with highest NIQE score: {video_path}\")\n",
    "\n",
    "# Capture the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "success, frame = cap.read()\n",
    "if success:\n",
    "    # Convert BGR to RGB for proper visualization\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Video: {highest_niqe_video['video_id']}\\nNIQE Score: {highest_niqe_video['niqe']}\")\n",
    "    plt.show()\n",
    "cap.release()\n"
   ],
   "id": "fe1f6026736bee10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plot the first frame of the video with the lowest NIQE score\n",
    "lowest_niqe_video = results[results[\"niqe\"] == results[\"niqe\"].min()].iloc[0]\n",
    "video_path = os.path.join(videos_path, lowest_niqe_video[\"video_id\"] + '.mp4')\n",
    "print(f\"Video with lowest NIQE score: {video_path}\")\n",
    "\n",
    "# Capture the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "success, frame = cap.read()\n",
    "if success:\n",
    "    # Convert BGR to RGB for proper visualization\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Video: {lowest_niqe_video['video_id']}\\nNIQE Score: {lowest_niqe_video['niqe']}\")\n",
    "    plt.show()"
   ],
   "id": "c9d87f48f089031c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "db04e8e1683e2cef",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
